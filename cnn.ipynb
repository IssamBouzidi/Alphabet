{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('alphabets': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a021cfdfd4194657ccdb1b0526c88d667e5e7bebd29be4a6848eecd6f81e74e9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), input_shape=(28,28,1), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=128, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=26, activation=\"softmax\")) # valeurs de units represente le nombre de valeurs de sortie, ici, c'est 26 nombre de lettre de l'alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 369792 images belonging to 26 classes.\n",
      "Found 329163 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory=\"data/TRAINING\", target_size=(28, 28), batch_size=32, class_mode=\"categorical\", color_mode=\"grayscale\")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(directory=\"data/TEST\", target_size=(28,28), batch_size=32, class_mode=\"categorical\", color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "361/361 [==============================] - 247s 685ms/step - loss: 1.8548 - accuracy: 0.4488 - val_loss: 1.1785 - val_accuracy: 0.6653\n",
      "Epoch 2/50\n",
      "361/361 [==============================] - 236s 653ms/step - loss: 1.1347 - accuracy: 0.6374 - val_loss: 0.6373 - val_accuracy: 0.7846\n",
      "Epoch 3/50\n",
      "361/361 [==============================] - 283s 784ms/step - loss: 0.8826 - accuracy: 0.7178 - val_loss: 0.6664 - val_accuracy: 0.8146\n",
      "Epoch 4/50\n",
      "361/361 [==============================] - 237s 657ms/step - loss: 0.7602 - accuracy: 0.7525 - val_loss: 0.4730 - val_accuracy: 0.8469\n",
      "Epoch 5/50\n",
      "361/361 [==============================] - 272s 755ms/step - loss: 0.6787 - accuracy: 0.7811 - val_loss: 0.3371 - val_accuracy: 0.8668\n",
      "Epoch 6/50\n",
      "361/361 [==============================] - 269s 745ms/step - loss: 0.6219 - accuracy: 0.8021 - val_loss: 0.4740 - val_accuracy: 0.8895\n",
      "Epoch 7/50\n",
      "361/361 [==============================] - 229s 635ms/step - loss: 0.5703 - accuracy: 0.8199 - val_loss: 0.1403 - val_accuracy: 0.8738\n",
      "Epoch 8/50\n",
      "361/361 [==============================] - 229s 635ms/step - loss: 0.5570 - accuracy: 0.8239 - val_loss: 0.3221 - val_accuracy: 0.8868\n",
      "Epoch 9/50\n",
      "361/361 [==============================] - 283s 784ms/step - loss: 0.5400 - accuracy: 0.8282 - val_loss: 0.2480 - val_accuracy: 0.8961\n",
      "Epoch 10/50\n",
      "361/361 [==============================] - 234s 647ms/step - loss: 0.5131 - accuracy: 0.8398 - val_loss: 0.0667 - val_accuracy: 0.9059\n",
      "Epoch 11/50\n",
      "361/361 [==============================] - 224s 622ms/step - loss: 0.4821 - accuracy: 0.8504 - val_loss: 0.2457 - val_accuracy: 0.8975\n",
      "Epoch 12/50\n",
      "361/361 [==============================] - 307s 850ms/step - loss: 0.4740 - accuracy: 0.8530 - val_loss: 0.7029 - val_accuracy: 0.9033\n",
      "Epoch 13/50\n",
      "361/361 [==============================] - 360s 996ms/step - loss: 0.4700 - accuracy: 0.8509 - val_loss: 0.2266 - val_accuracy: 0.9054\n",
      "Epoch 14/50\n",
      "361/361 [==============================] - 337s 935ms/step - loss: 0.4511 - accuracy: 0.8595 - val_loss: 0.3469 - val_accuracy: 0.9140\n",
      "Epoch 15/50\n",
      "361/361 [==============================] - 345s 955ms/step - loss: 0.4346 - accuracy: 0.8595 - val_loss: 0.1761 - val_accuracy: 0.9166\n",
      "Epoch 16/50\n",
      "361/361 [==============================] - 378s 1s/step - loss: 0.4142 - accuracy: 0.8722 - val_loss: 0.3140 - val_accuracy: 0.9206\n",
      "Epoch 17/50\n",
      "361/361 [==============================] - 339s 939ms/step - loss: 0.4222 - accuracy: 0.8681 - val_loss: 0.1063 - val_accuracy: 0.9173\n",
      "Epoch 18/50\n",
      "361/361 [==============================] - 343s 950ms/step - loss: 0.4030 - accuracy: 0.8730 - val_loss: 0.1988 - val_accuracy: 0.9219\n",
      "Epoch 19/50\n",
      "361/361 [==============================] - 336s 930ms/step - loss: 0.3933 - accuracy: 0.8802 - val_loss: 0.0761 - val_accuracy: 0.9206\n",
      "Epoch 20/50\n",
      "361/361 [==============================] - 384s 1s/step - loss: 0.4045 - accuracy: 0.8753 - val_loss: 0.4353 - val_accuracy: 0.9223\n",
      "Epoch 21/50\n",
      "361/361 [==============================] - 349s 966ms/step - loss: 0.3964 - accuracy: 0.8785 - val_loss: 0.3609 - val_accuracy: 0.9210\n",
      "Epoch 22/50\n",
      "361/361 [==============================] - 336s 932ms/step - loss: 0.3733 - accuracy: 0.8838 - val_loss: 0.2510 - val_accuracy: 0.9102\n",
      "Epoch 23/50\n",
      "361/361 [==============================] - 367s 1s/step - loss: 0.3765 - accuracy: 0.8847 - val_loss: 0.4770 - val_accuracy: 0.9196\n",
      "Epoch 24/50\n",
      "361/361 [==============================] - 337s 933ms/step - loss: 0.3655 - accuracy: 0.8873 - val_loss: 0.2394 - val_accuracy: 0.9260\n",
      "Epoch 25/50\n",
      "361/361 [==============================] - 345s 956ms/step - loss: 0.3633 - accuracy: 0.8846 - val_loss: 0.1651 - val_accuracy: 0.9312\n",
      "Epoch 26/50\n",
      "361/361 [==============================] - 336s 930ms/step - loss: 0.3604 - accuracy: 0.8855 - val_loss: 0.3615 - val_accuracy: 0.9312\n",
      "Epoch 27/50\n",
      "361/361 [==============================] - 364s 1s/step - loss: 0.3688 - accuracy: 0.8903 - val_loss: 0.2505 - val_accuracy: 0.9241\n",
      "Epoch 28/50\n",
      "361/361 [==============================] - 344s 953ms/step - loss: 0.3448 - accuracy: 0.8970 - val_loss: 0.3827 - val_accuracy: 0.9327\n",
      "Epoch 29/50\n",
      "361/361 [==============================] - 333s 923ms/step - loss: 0.3616 - accuracy: 0.8966 - val_loss: 0.2973 - val_accuracy: 0.9348\n",
      "Epoch 30/50\n",
      "361/361 [==============================] - 348s 963ms/step - loss: 0.3297 - accuracy: 0.8985 - val_loss: 0.2959 - val_accuracy: 0.9393\n",
      "Epoch 31/50\n",
      "361/361 [==============================] - 420s 1s/step - loss: 0.3366 - accuracy: 0.8933 - val_loss: 0.0801 - val_accuracy: 0.9289\n",
      "Epoch 32/50\n",
      "361/361 [==============================] - 451s 1s/step - loss: 0.3380 - accuracy: 0.8981 - val_loss: 0.2252 - val_accuracy: 0.9352\n",
      "Epoch 33/50\n",
      "361/361 [==============================] - 83s 230ms/step - loss: 0.3267 - accuracy: 0.9031 - val_loss: 0.0328 - val_accuracy: 0.9388\n",
      "Epoch 34/50\n",
      "361/361 [==============================] - 80s 222ms/step - loss: 0.3329 - accuracy: 0.8965 - val_loss: 0.2510 - val_accuracy: 0.9393\n",
      "Epoch 35/50\n",
      "361/361 [==============================] - 128s 355ms/step - loss: 0.3320 - accuracy: 0.8998 - val_loss: 0.1994 - val_accuracy: 0.9342\n",
      "Epoch 36/50\n",
      "361/361 [==============================] - 83s 230ms/step - loss: 0.3392 - accuracy: 0.8958 - val_loss: 0.2513 - val_accuracy: 0.9393\n",
      "Epoch 37/50\n",
      "361/361 [==============================] - 83s 230ms/step - loss: 0.3082 - accuracy: 0.9038 - val_loss: 0.2830 - val_accuracy: 0.9342\n",
      "Epoch 38/50\n",
      "361/361 [==============================] - 82s 228ms/step - loss: 0.3197 - accuracy: 0.9044 - val_loss: 0.0887 - val_accuracy: 0.9341\n",
      "Epoch 39/50\n",
      "361/361 [==============================] - 99s 275ms/step - loss: 0.3227 - accuracy: 0.9020 - val_loss: 0.2016 - val_accuracy: 0.9399\n",
      "Epoch 40/50\n",
      "361/361 [==============================] - 114s 316ms/step - loss: 0.3107 - accuracy: 0.9057 - val_loss: 0.1148 - val_accuracy: 0.9344\n",
      "Epoch 41/50\n",
      "361/361 [==============================] - 87s 242ms/step - loss: 0.3152 - accuracy: 0.9050 - val_loss: 0.2425 - val_accuracy: 0.9433\n",
      "Epoch 42/50\n",
      "361/361 [==============================] - 81s 226ms/step - loss: 0.3207 - accuracy: 0.9030 - val_loss: 0.0587 - val_accuracy: 0.9422\n",
      "Epoch 43/50\n",
      "361/361 [==============================] - 84s 233ms/step - loss: 0.3134 - accuracy: 0.9024 - val_loss: 0.1021 - val_accuracy: 0.9376\n",
      "Epoch 44/50\n",
      "361/361 [==============================] - 138s 381ms/step - loss: 0.2975 - accuracy: 0.9095 - val_loss: 0.0428 - val_accuracy: 0.9449\n",
      "Epoch 45/50\n",
      "361/361 [==============================] - 81s 226ms/step - loss: 0.3171 - accuracy: 0.9045 - val_loss: 0.2075 - val_accuracy: 0.9367\n",
      "Epoch 46/50\n",
      "361/361 [==============================] - 83s 229ms/step - loss: 0.2875 - accuracy: 0.9142 - val_loss: 0.4156 - val_accuracy: 0.9420\n",
      "Epoch 47/50\n",
      "361/361 [==============================] - 80s 223ms/step - loss: 0.3104 - accuracy: 0.9088 - val_loss: 0.1808 - val_accuracy: 0.9363\n",
      "Epoch 48/50\n",
      "361/361 [==============================] - 97s 269ms/step - loss: 0.2809 - accuracy: 0.9119 - val_loss: 0.1760 - val_accuracy: 0.9409\n",
      "Epoch 49/50\n",
      "361/361 [==============================] - 110s 304ms/step - loss: 0.2909 - accuracy: 0.9092 - val_loss: 0.1720 - val_accuracy: 0.9441\n",
      "Epoch 50/50\n",
      "361/361 [==============================] - 81s 223ms/step - loss: 0.2908 - accuracy: 0.9084 - val_loss: 0.1132 - val_accuracy: 0.9430\n"
     ]
    }
   ],
   "source": [
    "entrainement = model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=len(train_generator) // 32,\n",
    "    epochs=50, \n",
    "    validation_data=test_generator, \n",
    "    validation_steps=len(test_generator) // 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarder le model\n",
    "model.save('alphabet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du tableau des alphabets\n",
    "alphabet_array = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 11, 11, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 5, 5, 32)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 800)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               102528    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 26)                3354      \n=================================================================\nTotal params: 115,450\nTrainable params: 115,450\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from keras.preprocessing import image\n",
    "# from keras.models import load_model\n",
    "\n",
    "# choix = r'data/VALIDATION/ROI_1.png'\n",
    "# test_model = load_model('alphabet_model.h5')\n",
    "\n",
    "# test_image = image.load_img(choix, target_size = (28, 28), color_mode=\"grayscale\")\n",
    "# test_image = image.img_to_array(test_image)\n",
    "# test_image = np.expand_dims(test_image, axis = 0)\n",
    "# result = test_model.predict(test_image)\n",
    "# # train_generator.class_indices\n",
    "\n",
    "# preds = test_model.predict_classes(test_image)\n",
    "# prob = test_model.predict_proba(test_image)\n",
    "\n",
    "# index = preds[0]\n",
    "# print(f'Il s\\'agit de la lettre \"{alphabet_array[index]}\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}